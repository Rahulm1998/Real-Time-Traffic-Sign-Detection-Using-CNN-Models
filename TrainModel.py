from keras.models import Sequentialfrom keras.layers import Dense, Dropout, Activation, Flattenfrom keras.layers import Conv2D, MaxPooling2Dfrom keras.utils import to_categoricalfrom keras.callbacks import EarlyStoppingfrom keras.regularizers import l2#import  keras.regularizers as rimport matplotlib.pyplot as pltimport pickleimport numpy as npfrom keras.optimizers import SGD, Adam#import randomfrom tensorflow.keras.callbacks import TensorBoardimport tensorflow as tfimport osfrom test import testusdef  train_model():    #name="Twenty-classesV2"    #tb=TensorBoard(log_dir=os.path.join("logs\{}".format(name)))    pickle_in = open("X_train.pickle","rb")    X_train = pickle.load(pickle_in)    pickle_in = open("y_train.pickle","rb")    y_train= pickle.load(pickle_in)    pickle_in = open("X_test.pickle", "rb")    X_test = pickle.load(pickle_in)    pickle_in = open("y_test.pickle", "rb")    y_test = pickle.load(pickle_in)    print(max(y_test))    print("Data=loaded")    model = Sequential()    '''    model.add(Conv2D(32, (3, 3), padding='same',                     input_shape=X_train.shape[1:],                     activation='relu'))    model.add(Conv2D(32, (3, 3), activation='relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.25))    #model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))    model.add(Conv2D(64, (3, 3), activation='relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.25))    model.add(Conv2D(128, (3, 3), padding='same',activation='relu'))    model.add(Conv2D(128, (3, 3), activation='relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.25))    model.add(Flatten())    model.add(Dense(256, activation='relu'))    model.add(Dropout(0.5))    model.add(Dense(43, activation='softmax'))    sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)    model.compile(loss='categorical_crossentropy',                  optimizer=sgd,                  metrics=['accuracy'])    history=model.fit(X_train,to_categorical(np.array(y_train)), batch_size=32, epochs=5                      , validation_data=(X_test,to_categorical(np.array(y_test))), )'''    '''    #Twenty CLasses V1 Code    model.add(Conv2D(64, (5, 5), input_shape=X_train.shape[1:], activation=tf.nn.relu ))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.5))    model.add(Conv2D(40, (3,3), activation=tf.nn.relu))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.5))    model.add(Dense(64, activation='relu'))    model.add(Dropout(0.5))    model.add(Flatten())    model.add(Dense(43, activation='softmax'))    '''    '''    model.add(Conv2D(32,(3, 3),input_shape=X_train.shape[1:]), )    model.add(Activation('relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Conv2D(64, (3, 3), kernel_regularizer= r.l2(0.01)))    model.add(Activation('relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.25))    model.add(Conv2D(64, (3, 3), kernel_regularizer= r.l2(0.01)))    model.add(Activation('relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    #model.add(Dropout(0.25))    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors    model.add(Dense(128, kernel_regularizer= r.l2(0.01)))    model.add(Dropout(0.5))    model.add(Dense(43, activation='softmax'))'''    '''    model.add(Conv2D(64, (5, 5), input_shape=X_train.shape[1:]))    #model.add(BatchNormalization())    model.add(Activation('relu'))    model.add(MaxPooling2D(pool_size=(3, 3)),)    model.add(Conv2D(64, (3, 3)))    model.add(Activation('relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.25))    model.add(Conv2D(64, (3, 3)))    #model.add(BatchNormalization())    model.add(Activation('relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.25))    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors    model.add(Dense(128))    #model.add(BatchNormalization())    model.add(Dropout(0.5))    model.add(Dense(43, activation='softmax'))    '''    '''    #model = Sequential()    model.add((Conv2D(50, (5,5), input_shape=(X_train.shape[1:]), activation='relu', )))    #model.add((Conv2D(50, (5,5), activation='relu')))    model.add(MaxPooling2D(pool_size=(2,2)))    model.add(Dropout(0.25))    model.add((Conv2D(50 // 2, (3,3), activation='relu')))    model.add((Conv2D(50 // 2, (3, 3), activation='relu')))    model.add(MaxPooling2D(pool_size=(2,2)))    model.add(Dropout(0.25))    model.add(Flatten())    model.add(Dense(128, activation='relu',))    model.add(Dropout(0.5))    model.add(Dense(43, activation='softmax'))'''    model.add((Conv2D(20, (5, 5), input_shape=(X_train.shape[1:]), activation='relu')))    #model.add((Conv2D(20, (5,5), activation='relu')))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.25))    #model.add((Conv2D(40, (3, 3), activation='relu')))    model.add((Conv2D(40, (3, 3), activation='relu')))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.25))    model.add(Flatten())    model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))    model.add(Dropout(0.5))    model.add(Dense(43, activation='softmax',kernel_regularizer=l2(0.01)))    #sgd = SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True)    model.compile(Adam(lr=.001), loss='categorical_crossentropy', metrics=['accuracy'])    # model.compile(loss='categorical_crossentropy',    #               optimizer=sgd,    #               metrics=['accuracy'])    # history=model.fit(X_train,to_categorical(np.array(y_train)), batch_size=32, epochs=15    #                   , validation_data=(X_test,to_categorical(np.array(y_test))), )    #early = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')    history = model.fit(X_train,to_categorical(np.array(y_train)) , batch_size=32,                                   epochs=20,                                  validation_data=(X_test, to_categorical(np.array(y_test))), shuffle=1)    pickle_out = open("Forty_Three(08-5-20).p", "wb")    pickle.dump(model, pickle_out)    pickle_out.close()    plt.plot(history.history['accuracy'])    plt.plot(history.history['val_accuracy'])    plt.title('Model accuracy')    plt.ylabel('Accuracy')    plt.xlabel('Epoch')    plt.legend(['Train', 'Test'], loc='upper left')    plt.show()    #Plot training & validation loss values    plt.plot(history.history['loss'])    plt.plot(history.history['val_loss'])    plt.title('Model loss')    plt.ylabel('Loss')    plt.xlabel('Epoch')    plt.legend(['Train', 'Test'], loc='upper left')    plt.show()train_model()testus()